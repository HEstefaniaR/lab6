{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "adf55b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import os\n",
    "import re\n",
    "\n",
    "customer_df = pd.read_csv(\"../data/raw/customer_data.csv\")\n",
    "retail_df = pd.read_csv(\"../data/raw/retail_data.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42e15657",
   "metadata": {},
   "source": [
    "# Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2939becf",
   "metadata": {},
   "source": [
    "Customer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "25b11b6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombres de columnas normalizados.\n",
      "signup_date limpiado y validado correctamente.\n",
      "email limpiado, validado y sin duplicados correctamente.\n",
      "Se encontraron 314 teléfonos inválidos. Asignando números consecutivos...\n",
      "phone limpiado y validado correctamente.\n",
      "age limpiado y validado correctamente.\n",
      "gender limpiado y normalizado correctamente.\n",
      "address y full_name limpiados correctamente.\n"
     ]
    }
   ],
   "source": [
    "# --- 1. Normalizar nombres de columnas ---\n",
    "customer_df.columns = customer_df.columns.str.strip().str.lower()\n",
    "print(\"Nombres de columnas normalizados.\")\n",
    "\n",
    "# --- 2. signup_date: validar rango y corregir ---\n",
    "customer_df['signup_date'] = pd.to_datetime(customer_df['signup_date'], errors='coerce')\n",
    "\n",
    "min_signup = pd.Timestamp(\"2020-01-01\")\n",
    "max_signup = pd.Timestamp.today().normalize()\n",
    "\n",
    "# Reemplazar inválidas por la fecha más reciente\n",
    "customer_df['signup_date'] = customer_df['signup_date'].apply(\n",
    "    lambda x: max_signup if pd.isna(x) or x < min_signup or x > max_signup else x\n",
    ")\n",
    "\n",
    "print(\"signup_date limpiado y validado correctamente.\")\n",
    "\n",
    "# --- 3. email: limpiar, validar y asegurar unicidad ---\n",
    "email_regex = (\n",
    "    r\"^(?!\\.)[A-Za-z0-9._%+-]+@\"\n",
    "    r\"(?!-)[A-Za-z0-9-]+(\\.[A-Za-z0-9-]+)*\\.[A-Za-z]{2,}$\"\n",
    ")\n",
    "\n",
    "def fix_email(row):\n",
    "    email = str(row['email']).strip()\n",
    "    if pd.isna(email) or not re.match(email_regex, email):\n",
    "        return f\"unknown_{row['id']}@domain.com\"\n",
    "    return email\n",
    "\n",
    "customer_df['email'] = customer_df.apply(fix_email, axis=1)\n",
    "\n",
    "# Resolver duplicados agregando índice\n",
    "dup_emails = customer_df.duplicated(subset=['email'], keep=False)\n",
    "if dup_emails.any():\n",
    "    print(f\"Se encontraron {dup_emails.sum()} emails duplicados, corrigiendo...\")\n",
    "    customer_df.loc[dup_emails, 'email'] = (\n",
    "        customer_df.loc[dup_emails, 'email'] + \"_\" + customer_df.loc[dup_emails].index.astype(str)\n",
    "    )\n",
    "\n",
    "print(\"email limpiado, validado y sin duplicados correctamente.\")\n",
    "\n",
    "# --- 4. phone: limpiar, corregir y asegurar unicidad ---\n",
    "customer_df['phone'] = customer_df['phone'].astype(str).str.replace(r'\\D', '', regex=True)\n",
    "\n",
    "# Identificar números inválidos (distintos de 10 dígitos)\n",
    "invalid_mask = customer_df['phone'].apply(lambda x: len(x) != 10)\n",
    "\n",
    "if invalid_mask.any():\n",
    "    invalid_count = invalid_mask.sum()\n",
    "    print(f\"Se encontraron {invalid_count} teléfonos inválidos. Asignando números consecutivos...\")\n",
    "\n",
    "    # Crear nuevos números consecutivos de 10 dígitos\n",
    "    new_phones = [str(i).zfill(10) for i in range(invalid_count)]\n",
    "    customer_df.loc[invalid_mask, 'phone'] = new_phones\n",
    "\n",
    "# Asegurar unicidad agregando sufijo si quedan duplicados\n",
    "dup_phones = customer_df.duplicated(subset=['phone'], keep=False)\n",
    "if dup_phones.any():\n",
    "    print(f\"Se encontraron {dup_phones.sum()} teléfonos duplicados. Corrigiendo...\")\n",
    "    customer_df.loc[dup_phones, 'phone'] = (\n",
    "        customer_df.loc[dup_phones, 'phone'] + \"_\" + customer_df.loc[dup_phones].index.astype(str)\n",
    "    )\n",
    "\n",
    "print(\"phone limpiado y validado correctamente.\")\n",
    "\n",
    "# --- 5. age: forzar rango 18-100 ---\n",
    "customer_df['age'] = pd.to_numeric(customer_df['age'], errors='coerce').fillna(18).astype(int)\n",
    "customer_df['age'] = customer_df['age'].clip(lower=18, upper=100)\n",
    "\n",
    "print(\"age limpiado y validado correctamente.\")\n",
    "\n",
    "# --- 6. gender: normalizar y validar ---\n",
    "customer_df['gender'] = customer_df['gender'].astype(str).str.strip().str.capitalize()\n",
    "valid_genders = [\"Male\", \"Female\", \"M\", \"F\", \"Other\"]\n",
    "customer_df['gender'] = customer_df['gender'].apply(lambda x: x if x in valid_genders else \"Other\")\n",
    "\n",
    "print(\"gender limpiado y normalizado correctamente.\")\n",
    "\n",
    "# --- 7. address y full_name: llenar nulos ---\n",
    "customer_df['address'].fillna(\"Unknown Address\", inplace=True)\n",
    "customer_df['full_name'].fillna(\"Unknown\", inplace=True)\n",
    "\n",
    "print(\"address y full_name limpiados correctamente.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f59c622",
   "metadata": {},
   "source": [
    "Retail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bc3d6a01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se encontraron 720 duplicados en 'transaction_id'. Corrigiendo...\n",
      "transaction_id corregido, sin eliminar registros.\n",
      "purchase_date limpiado y validado correctamente.\n",
      "amount limpiado y validado correctamente.\n",
      "product_category limpiado correctamente.\n"
     ]
    }
   ],
   "source": [
    "# --- 1. transaction_id: asegurar unicidad sin eliminar ---\n",
    "retail_df['transaction_id'] = retail_df['transaction_id'].astype(str).str.strip()\n",
    "retail_df['transaction_id'] = retail_df['transaction_id'].replace(['', 'nan', 'None'], pd.NA)\n",
    "\n",
    "# Paso 1: obtener máximo ID actual\n",
    "max_id = pd.to_numeric(retail_df['transaction_id'], errors='coerce').max(skipna=True)\n",
    "if pd.isna(max_id):\n",
    "    max_id = 0\n",
    "\n",
    "# Paso 2: asignar IDs a los nulos\n",
    "missing_count = retail_df['transaction_id'].isna().sum()\n",
    "if missing_count > 0:\n",
    "    new_ids = range(int(max_id) + 1, int(max_id) + missing_count + 1)\n",
    "    retail_df.loc[retail_df['transaction_id'].isna(), 'transaction_id'] = [str(i) for i in new_ids]\n",
    "    print(f\"Se asignaron {missing_count} nuevos transaction_id.\")\n",
    "\n",
    "# Paso 3: corregir duplicados con IDs consecutivos\n",
    "duplicados = retail_df.duplicated(subset=[\"transaction_id\"], keep=\"first\")\n",
    "if duplicados.any():\n",
    "    dup_count = duplicados.sum()\n",
    "    print(f\"Se encontraron {dup_count} duplicados en 'transaction_id'. Corrigiendo...\")\n",
    "\n",
    "    max_id = pd.to_numeric(retail_df['transaction_id'], errors='coerce').max()\n",
    "    new_dup_ids = range(int(max_id) + 1, int(max_id) + dup_count + 1)\n",
    "    retail_df.loc[duplicados, 'transaction_id'] = [str(i) for i in new_dup_ids]\n",
    "\n",
    "print(\"transaction_id corregido, sin eliminar registros.\")\n",
    "\n",
    "# --- 2. purchase_date: validar y ajustar rango ---\n",
    "retail_df['purchase_date'] = pd.to_datetime(retail_df['purchase_date'], errors='coerce')\n",
    "\n",
    "min_date = pd.Timestamp(\"2025-01-01\")\n",
    "max_date = pd.Timestamp.today().normalize()\n",
    "\n",
    "retail_df['purchase_date'] = retail_df['purchase_date'].apply(\n",
    "    lambda x: min_date if pd.isna(x) or x < min_date else (max_date if x > max_date else x)\n",
    ")\n",
    "\n",
    "print(\"purchase_date limpiado y validado correctamente.\")\n",
    "\n",
    "# --- 3. amount: convertir a float y limitar rango ---\n",
    "retail_df['amount'] = pd.to_numeric(retail_df['amount'], errors='coerce')\n",
    "retail_df['amount'].fillna(0.01, inplace=True)\n",
    "retail_df['amount'] = retail_df['amount'].clip(lower=0.01, upper=10000)\n",
    "\n",
    "print(\"amount limpiado y validado correctamente.\")\n",
    "\n",
    "# --- 4. product_category: llenar nulos y vacíos ---\n",
    "retail_df['product_category'].fillna('No specified', inplace=True)\n",
    "retail_df['product_category'].replace(\"\", \"No specified\", inplace=True)\n",
    "\n",
    "print(\"product_category limpiado correctamente.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c8f7b60b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Customer Data ---\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 9 columns):\n",
      " #   Column       Non-Null Count  Dtype         \n",
      "---  ------       --------------  -----         \n",
      " 0   id           1000 non-null   int64         \n",
      " 1   full_name    1000 non-null   object        \n",
      " 2   email        1000 non-null   object        \n",
      " 3   phone        1000 non-null   object        \n",
      " 4   address      1000 non-null   object        \n",
      " 5   signup_date  1000 non-null   datetime64[ns]\n",
      " 6   name         1000 non-null   object        \n",
      " 7   gender       1000 non-null   object        \n",
      " 8   age          1000 non-null   int64         \n",
      "dtypes: datetime64[ns](1), int64(2), object(6)\n",
      "memory usage: 70.4+ KB\n",
      "None\n",
      "\n",
      "Nulos por columna:\n",
      "id             0\n",
      "full_name      0\n",
      "email          0\n",
      "phone          0\n",
      "address        0\n",
      "signup_date    0\n",
      "name           0\n",
      "gender         0\n",
      "age            0\n",
      "dtype: int64\n",
      "\n",
      "--- Retail Data ---\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 820 entries, 0 to 819\n",
      "Data columns (total 5 columns):\n",
      " #   Column            Non-Null Count  Dtype         \n",
      "---  ------            --------------  -----         \n",
      " 0   customer_id       820 non-null    int64         \n",
      " 1   purchase_date     820 non-null    datetime64[ns]\n",
      " 2   product_category  820 non-null    object        \n",
      " 3   amount            820 non-null    float64       \n",
      " 4   transaction_id    820 non-null    object        \n",
      "dtypes: datetime64[ns](1), float64(1), int64(1), object(2)\n",
      "memory usage: 32.2+ KB\n",
      "None\n",
      "\n",
      "Nulos por columna:\n",
      "customer_id         0\n",
      "purchase_date       0\n",
      "product_category    0\n",
      "amount              0\n",
      "transaction_id      0\n",
      "dtype: int64\n",
      "\n",
      "Limpieza completada correctamente.\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Customer Data ---\")\n",
    "print(customer_df.info())\n",
    "print(\"\\nNulos por columna:\")\n",
    "print(customer_df.isnull().sum())\n",
    "\n",
    "print(\"\\n--- Retail Data ---\")\n",
    "print(retail_df.info())\n",
    "print(\"\\nNulos por columna:\")\n",
    "print(retail_df.isnull().sum())\n",
    "\n",
    "print(\"\\nLimpieza completada correctamente.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e7fa11fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned customer data saved at: ../data/clean/customer_data_clean.csv\n",
      "Cleaned retail data saved at: ../data/clean/retail_data_clean.csv\n"
     ]
    }
   ],
   "source": [
    "customer_df.reset_index(drop=True, inplace=True)\n",
    "retail_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Crear carpeta clean si no existe\n",
    "os.makedirs(\"../data/clean\", exist_ok=True)\n",
    "\n",
    "# Rutas de guardado\n",
    "customer_clean_path = \"../data/clean/customer_data_clean.csv\"\n",
    "retail_clean_path = \"../data/clean/retail_data_clean.csv\"\n",
    "\n",
    "# Guardar los CSV limpios\n",
    "customer_df.to_csv(customer_clean_path, index=False)\n",
    "retail_df.to_csv(retail_clean_path, index=False)\n",
    "\n",
    "print(f\"Cleaned customer data saved at: {customer_clean_path}\")\n",
    "print(f\"Cleaned retail data saved at: {retail_clean_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
